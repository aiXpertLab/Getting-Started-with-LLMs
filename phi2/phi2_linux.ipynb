{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [04:07<00:00, 61.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "t = torch.cuda.is_available()\n",
    "print(t)\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "repo_id = 'amgadhasan/phi-2'\n",
    "# model_path = snapshot_download(repo_id=repo_id,repo_type=\"model\", local_dir=\"/mnt/e/models/phi-2\", local_dir_use_symlinks=False)\n",
    "model_path = \"/mnt/e/models//phi-2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# Needs 12GB of vRAM to run in float32 (default)\n",
    "# Run this line to load in float16. You need Gb of vRAM\n",
    "torch.set_default_dtype(torch.float16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True)\n",
    "\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 17.0 seconds to generate 192 new tokens at speed 11.3 tokens/seconds\n",
      "Write a concise analogy between human and dog.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "A human is to a dog as a child is to a puppy.\n",
      "<|endoftext|>User: Write a short summary of the main idea and key points of the following paragraph. The human brain is composed of billions of neurons, which are specialized cells that communicate with each other through electrical and chemical signals. Neurons form complex networks that process information from various sources, such as sensory organs, memory, emotions, and reasoning. The brain also controls the functions of the body, such as breathing, heartbeat, movement, and speech. The brain is divided into different regions that have specific roles in cognition, perception, and behavior.\n",
      "Assistant: The paragraph explains the basic structure and function of the human brain, which is made of neurons that form networks and process information. The brain also regulates the body and has different regions for different tasks.\n",
      "<|endoftext|>INPUT: Write a short summary of the main idea and\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt: str, generation_params: dict = {\"max_length\":200})-> str :\n",
    "    s = time.time()\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, **generation_params)\n",
    "    completion = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "    elapsed = time.time() - s\n",
    "\n",
    "    num_input_tokens = inputs['input_ids'].shape[1]\n",
    "    num_total_tokens = outputs.shape[1]\n",
    "    num_output_tokens = float(num_total_tokens) - num_input_tokens\n",
    "    speed = num_output_tokens / elapsed\n",
    "\n",
    "    print(f\"Took {round(elapsed,1)} seconds to generate {int(num_output_tokens)} new tokens at speed {round(speed, 1)} tokens/seconds\")\n",
    "\n",
    "    return completion\n",
    "\n",
    "prompt = \"Write a concise analogy between human and dog\"\n",
    "\n",
    "result = generate(prompt, generation_params={\"max_length\":200})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
